{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Linear Programs with Gurobi Optimizer\n",
    "\n",
    "This notebook contains two examples of how to formulate and solve linear programs using Python and Gurobi. The first example is the \"Bag Production\" problem from class. The second example is the \"Inventory Management\" example from class.\n",
    "\n",
    "## Example 1: Bag Production\n",
    "\n",
    "Recall that the linear program for the bag production problem is given by \n",
    "\n",
    "\\begin{align}\n",
    "\\underset{x_S, x_D}{\\text{max}} \\;\\; & 10 x_s + 8 x_D\\\\\n",
    "\\text{s.t.} \\;\\; &\\frac{7}{10} x_S + x_D \\le 630 \\\\\n",
    "& \\frac{1}{2} x_S + \\frac{5}{6} x_D \\le 600 \\\\\n",
    "& x_S + \\frac{2}{3} x_D \\le 708 \\\\\n",
    "& \\frac{1}{10}x_S + \\frac{1}{4} x_D \\le 135  \\\\\n",
    "& x_S, x_D \\ge 0.\n",
    "\\end{align}\n",
    "\n",
    "To solve the LP above, we first load the Gurobi module into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gurobipy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now formulate the LP using functions provided by the Gurobi module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using license file /Users/vagrant/gurobi.lic\n",
      "Academic license - for non-commercial use only\n"
     ]
    }
   ],
   "source": [
    "# Construct a 'blank' model. \n",
    "mod = Model()\n",
    "\n",
    "# Define decision variables. We will use variable names 'S' and 'D' for simplicity.\n",
    "S = mod.addVar()\n",
    "D = mod.addVar()\n",
    "\n",
    "# Construct constraints.\n",
    "cutting_con = mod.addConstr((7/10)*S + D  <= 630)\n",
    "sewing_con =  mod.addConstr((1/2)*S + (5/6)*D  <= 600)\n",
    "finishing_con =  mod.addConstr(S + (2/3)*D  <= 708)\n",
    "inspecting_con = mod.addConstr((1/10)*S + (1/4)*D  <= 135)\n",
    "\n",
    "# Add non-negativity constraints.\n",
    "mod.addConstr(S >= 0.0)\n",
    "mod.addConstr(D >= 0.0)\n",
    "\n",
    "# Create the objective function, and set it to be maximized.\n",
    "mod.setObjective(10*S + 9*D, GRB.MAXIMIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now push the updated constraints and objective to the blank model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is set up, we can call Gurobi to solve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (mac64)\n",
      "Optimize a model with 6 rows, 2 columns and 10 nonzeros\n",
      "Model fingerprint: 0x7cdc10a6\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-01, 1e+00]\n",
      "  Objective range  [9e+00, 1e+01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+02, 7e+02]\n",
      "Presolve removed 2 rows and 0 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 4 rows, 2 columns, 8 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    9.0000000e+03   4.791138e+01   0.000000e+00      0s\n",
      "       2    7.6680000e+03   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.03 seconds\n",
      "Optimal objective  7.668000000e+03\n"
     ]
    }
   ],
   "source": [
    "mod.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we solve the problem, we can retrieve the optimal solution found by Gurobi and the associated optimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved to optimality\n",
      "Number of Standard bags:  539.9999999999999\n",
      "Number of Deluxe bags:  252.0000000000001\n",
      "Optimal profit: 7668.0\n"
     ]
    }
   ],
   "source": [
    "# Extract the solution status. \n",
    "if mod.status == GRB.OPTIMAL:\n",
    "    print(\"Solved to optimality\")\n",
    "    \n",
    "# Extract the optimal values of the decision variables.\n",
    "S_opt = S.x\n",
    "D_opt = D.x\n",
    "\n",
    "print(\"Number of Standard bags: \", S_opt)\n",
    "print(\"Number of Deluxe bags: \", D_opt)\n",
    "\n",
    "# Retrieve the optimal value.\n",
    "opt_val = mod.objval\n",
    "print(\"Optimal profit:\", opt_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Product Delivery\n",
    "\n",
    "For the product delivery problem, it may be impractical to write the constraints explicitly if the number of warehouses and/or customers is large. Instead, we will import the data from .csv files. Recall that the linear program is given by\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\underset{{\\bf x}}{\\text{min}} \\;\\; & \\sum_{i=1}^m \\sum_{j=1}^n c_{ij} x_{ij} \\\\\n",
    "\\text{s.t.} & \\sum_{i=1}^m x_{ij} \\ge d_j, \\quad j = 1,2,\\ldots,n, \\\\\n",
    "& \\sum_{j=1}^n x_{ij} \\le s_i, \\quad i = 1,2,\\ldots,m, \\\\\n",
    "& x_{ij} \\ge 0, \\quad i = 1,2,\\ldots,m, \\; j = 1,2,\\ldots,n.\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "First, we read in the model parameters using the numpy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "demand = genfromtxt('demand.csv', delimiter=',')\n",
    "supply = genfromtxt('supply.csv', delimiter=',')\n",
    "cost = genfromtxt('cost.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now formulate the constraints and objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the data \n",
    "m = 10;\n",
    "n = 500;\n",
    "\n",
    "# Initialize the model \n",
    "mod = Model()\n",
    "\n",
    "# Define variables \n",
    "# mod.addVars(m,n) will create variables where rows are indexed from 0 to m-1 and columns are indexed from 0 to n-1 \n",
    "x = mod.addVars(m,n)\n",
    "\n",
    "# Constraint: All demands must be satisfied\n",
    "demand_con = {}\n",
    "for j in range(n):\n",
    "    demand_con[j] = mod.addConstr(sum(x[i,j] for i in range(m)) >= demand[j])\n",
    "    \n",
    "# Constraint: Total delivery from each warehouse cannot exceed available supply\n",
    "supply_con = {}\n",
    "for i in range(m):\n",
    "    supply_con[j] = mod.addConstr(sum(x[i,j] for j in range(n)) <= supply[i])\n",
    "    \n",
    "# Nonnegativity constraints:\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        mod.addConstr(x[i,j] >= 0.0)\n",
    "\n",
    "# Construct objective\n",
    "mod.setObjective(sum(cost[i][j] * x[i,j] for i in range(m) for j in range(n)), GRB.MINIMIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the constraints are written in a form that closely resemble the mathematical expressions in the LP formulation -- this readability is one of the advantages of using the Gurobi package in Python to build and solve optimization models. \n",
    "\n",
    "Next, we update and solve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "Optimize a model with 5510 rows, 5000 columns and 15000 nonzeros\n",
      "Model fingerprint: 0x15cb881c\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e-06, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e-03, 1e+02]\n",
      "Presolve removed 5000 rows and 0 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 510 rows, 5000 columns, 10000 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   3.142678e+01   0.000000e+00      0s\n",
      "     577    2.5642351e+01   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 577 iterations and 0.02 seconds\n",
      "Optimal objective  2.564235109e+01\n"
     ]
    }
   ],
   "source": [
    "# Update and solve\n",
    "mod.update()\n",
    "mod.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the output provides the number of simplex algorithm iterations taken to solve the LP.  \n",
    "\n",
    "As in Example 1, we can now retrieve the optimal solution and optimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal cost: 25.642351091747752\n",
      "[0.0, 0.0, 0.79442612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.65808973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.62451576, 0.18313888, 0.0, 0.89630676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99956897, 0.55641985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.80288216, 0.0, 0.0, 0.0, 0.65559661, 0.0, 0.0, 0.0, 0.0, 0.27034121, 0.0, 0.0, 0.0, 0.0, 0.49900153, 0.0, 0.0, 0.78831782, 0.0, 0.47949353, 0.0, 0.68921674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.68327286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34346244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.74789833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.83729652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6044689, 0.71418836, 0.25696758, 0.0, 0.65410904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29523295, 0.0, 0.71142798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.82216781, 0.61511221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.60749366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.53247743, 0.0, 0.0, 0.87951413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24322004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.64217539, 0.0, 0.0, 0.78389377, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39841906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.78886239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9944148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75202846, 0.0, 0.0, 0.0, 0.37660098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40711552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.88524399, 0.0, 0.0, 0.33894856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.85510668, 0.0, 0.0, 0.82595163, 0.0, 0.23044472, 0.0, 0.53349888, 0.769709, 0.12009485, 0.46545708, 0.0, 0.18887598, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06129547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.78452388, 0.0, 0.30347989, 0.0, 0.0, 0.78159635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.73861539, 0.68983163, 0.0, 0.0, 0.0, 0.0, 0.90706408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04510912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6252557, 0.0, 0.0, 0.0, 0.55196388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21006282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30526007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.80368767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03169356, 0.0, 0.0, 0.812815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.46898984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16468573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08971565, 0.0, 0.0, 0.0, 0.0, 0.79611923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16333193, 0.0, 0.0, 0.0, 0.0, 0.14976528, 0.89585154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.76567006, 0.0, 0.0, 0.0, 0.0, 0.125552, 0.0, 0.16270587, 0.0, 0.69852052, 0.96277179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41947836, 0.0, 0.96718217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20031325, 0.0, 0.0, 0.73540839, 0.0, 0.0, 0.0, 0.0, 0.61412336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01375895, 0.0, 0.0, 0.0, 0.0, 0.10673528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.54752225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.97173771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4471811, 0.0, 0.54428102, 0.0, 0.0, 0.0, 0.0, 0.6719484, 0.0, 0.0, 0.48049689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15425341, 0.0, 0.0, 0.0, 0.0, 0.23290269, 0.39158843, 0.0, 0.53174474, 0.0, 0.18590074, 0.0, 0.0, 0.0, 0.53846803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.65138968, 0.15520205, 0.0, 0.0, 0.0, 0.0, 0.72278534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02887738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.53716856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96793019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45214915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34305754, 0.0, 0.0, 0.0, 0.28667711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.71830324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.70860971, 0.0, 0.12430757, 0.0, 0.0, 0.81666956, 0.54753283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7075335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08553424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24089405, 0.0, 0.0, 0.0, 0.0, 0.56367924, 0.0, 0.0, 0.78928187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.73799094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08279635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6369076, 0.0, 0.0, 0.0, 0.0, 0.60180362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21346292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08978604, 0.0, 0.10215484, 0.0, 0.26847091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49512499, 0.0, 0.63268411, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56013016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.92134764, 0.0, 0.0, 0.0, 0.61752472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43470017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33086002, 0.0, 0.0, 0.0, 0.32076487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.95557452, 0.48775157, 0.0, 0.0, 0.12789412, 0.19459782, 0.0, 0.00614059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.59479603, 0.0, 0.0, 0.0, 0.0, 0.10552198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.68336638, 0.17853768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.60617619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4967224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.69313551, 0.0, 0.95152569, 0.0, 0.0, 0.0, 0.0, 0.83829985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13016578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9055699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41448913, 0.0, 0.0, 0.0, 0.16491902, 0.52816711, 0.0, 0.14652309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36582963, 0.0, 0.0, 0.0, 0.0, 0.21633807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49491574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.72516145, 0.0, 0.0, 0.0, 0.02053143, 0.0, 0.66886132, 0.60673112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12005222, 0.0, 0.0, 0.21504648, 0.0, 0.0, 0.16794043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08152387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.62489654, 0.55684536, 0.0, 0.2784095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.59071693, 0.0, 0.0, 0.0, 0.0, 0.50536709, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38908391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29631184, 0.0, 0.0, 0.0, 0.0, 0.76269853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.97748396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.91599727, 0.0, 0.0, 0.0, 0.0, 0.08376819, 0.0, 0.0, 0.0, 0.95405573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.82632236, 0.0, 0.0, 0.0, 0.60744594, 0.33600765, 0.0, 0.0, 0.0, 0.0, 0.50269476, 0.0, 0.22494446999999745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.54123886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19779855, 0.0, 0.0, 0.0, 0.43167288, 0.55778485, 0.0, 0.0, 0.87313383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09897014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19003552, 0.0, 0.6540494, 0.0, 0.0, 0.0, 0.3992156, 0.0, 0.21738805, 0.0, 0.54692815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7961825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5151042, 0.0, 0.0, 0.0, 0.1453343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.74195755, 0.0, 0.0, 0.96352103, 0.77983661, 0.0, 0.0, 0.0, 0.93860458, 0.0, 0.0, 0.0, 0.70178237, 0.0, 0.67804845, 0.0, 0.0, 0.0, 0.0, 0.63886541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21841469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13617821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.82440298, 0.0, 0.0, 0.36201799, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23699816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42844356, 0.7761263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.85974082, 0.0, 0.0, 0.0, 0.0, 0.33427644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.71842703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.80405936, 0.8683312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21005182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9005975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22960069, 0.0, 0.0, 0.0, 0.0, 0.0, 0.81859792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43781127, 0.0, 0.34310689, 0.0, 0.86316634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26404933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37266922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8342229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12058088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47438722, 0.0, 0.51312771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0706934, 0.0, 0.0, 0.0, 0.40746728, 0.0, 0.0, 0.0, 0.0, 0.56849735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.64448426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.86950951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.72551629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56774902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.65857106, 0.0, 0.72121264, 0.0, 0.0, 0.36337362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04349403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.68111873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.571495, 0.02802203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3159536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.79193731, 0.0, 0.0, 0.0, 0.0, 0.15511798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.66348003, 0.0, 0.0, 0.7735105, 0.0, 0.0, 0.27409927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43413189999999247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04863476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.59955671, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.79596457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.68446896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.62946922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29349925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35316556700000035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37204889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.55123776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23512312, 0.0, 0.0, 0.7176973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39406152, 0.0, 0.0, 0.0, 0.7057389, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11235019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1515275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.69837503, 0.54897651, 0.74381355, 0.0, 0.13143658, 0.14554662, 0.0, 0.0, 0.0, 0.12229251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.74804755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32637336, 0.0, 0.0, 0.90478293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26213602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2721658, 0.66193671, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23039384, 0.0, 0.0, 0.0, 0.0, 0.37269293, 0.0, 0.0, 0.04958256, 0.91252916, 0.0, 0.01550591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.63556333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.78935639, 0.0, 0.0, 0.87730503, 0.45991685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39872457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38175265, 0.0, 0.07777508, 0.0, 0.0, 0.86365432, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02347478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7053263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.55529425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7726311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36695897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36672936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22517676, 0.0, 0.0, 0.0, 0.77200297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.59424694, 0.0, 0.0, 0.46991057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.64409455, 0.0, 0.0, 0.91883533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38960523, 0.56136583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5327277, 0.0, 0.0, 0.0, 0.0, 0.19862963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.91162722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.53241843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.65969237, 0.0, 0.04885473000000751, 0.0, 0.0, 0.0, 0.52255305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08078749, 0.0, 0.0, 0.0, 0.0, 0.90123994, 0.0, 0.7743605, 0.0, 0.10040421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28168404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.62821226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.82801759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56557165, 0.77614107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.78549411, 0.0, 0.0, 0.0, 0.57226406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34005555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.86608243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.80158607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.66950842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.94935806, 0.0, 0.37015122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.97802689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6281875, 0.63022122, 0.0, 0.0, 0.46772909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.98413949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33770809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16683074, 0.0, 0.0, 0.0, 0.89019551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.80896175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.78304707, 0.0, 0.0, 0.0, 0.91477897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33821084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3326616970000036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26255727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29902855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.92642177, 0.0, 0.0, 0.20105905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.72895764, 0.0, 0.0, 0.0, 0.53779354, 0.0, 0.75870826, 0.0, 0.0, 0.6353327529999997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.90654941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.69493925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07483279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.86887731, 0.0, 0.1054832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36608553, 0.21915791, 0.0, 0.0, 0.0, 0.65478453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.88743624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1154271, 0.0, 0.0, 0.0, 0.50932228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.74593766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.52717923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.57039433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44604317, 0.0, 0.0, 0.0, 0.08529087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18883782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.273282, 0.95643539, 0.0, 0.0, 0.13090837, 0.0, 0.0, 0.0, 0.90856743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24703742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.74239653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22402898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56335489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25392364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13760752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17230373, 0.83479968, 0.0, 0.0, 0.0, 0.0, 0.15203313, 0.0, 0.28677376, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23066488, 0.0, 0.0, 0.0, 0.87195872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39844849, 0.0, 0.0, 0.0, 0.0, 0.78290246, 0.10503808, 0.29194328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48789672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56462564, 0.0, 0.0, 0.0, 0.31859368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05788017, 0.0, 0.0, 0.5564649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12183821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34436703, 0.0, 0.0, 0.0, 0.0, 0.06073617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10131465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13303942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26583729299999637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13607154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99507338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.70841845, 0.0, 0.08908855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.60865329, 0.0, 0.28603817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.85762705, 0.95895133, 0.0, 0.75628231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.58003095, 0.0, 0.0, 0.0, 0.10695958, 0.0, 0.25563249, 0.04579922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8020741, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5329396, 0.0, 0.58249798, 0.65944305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33980309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7388679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.66328241, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09531903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01206114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.89504784, 0.0, 0.21068549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15359617, 0.55537358, 0.0, 0.34672391, 0.11946368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.57016303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49011717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27597735, 0.4817993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30316182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49325612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15695407, 0.0, 0.72127855, 0.0, 0.54787547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33085303, 0.0, 0.0, 0.0, 0.74206472, 0.0, 0.0, 0.0, 0.35175892, 0.0, 0.03416874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40714059, 0.0, 0.0, 0.29975766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35603002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.73660709, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.78277158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.53490798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00950552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75785736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16497568, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30054848, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.69642175, 0.0, 0.86776246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05962421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47610412, 0.09335969, 0.0, 0.45037665, 0.0, 0.0, 0.93691835, 0.79744845, 0.0, 0.0, 0.0, 0.23747351, 0.46814743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18057061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.98739157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.77698109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37992179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44091888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09809998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00366211, 0.0, 0.0, 0.0, 0.0, 0.5306181, 0.0, 0.0, 0.70368436, 0.0, 0.0, 0.78155002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35389746, 0.0, 0.53830773, 0.0, 0.0, 0.0, 0.83811602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10404763, 0.0, 0.92500299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5121456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05356108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.60040255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10108692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7078726, 0.0, 0.0, 0.0, 0.58766509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12267184, 0.81696597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44453814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13522465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34476992, 0.0, 0.76332456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.70849139, 0.31619553, 0.0, 0.0, 0.0, 0.27856204, 0.0, 0.31782356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47385086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.93810169, 0.0, 0.75761987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.77392802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.92676974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27603008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.70962976, 0.88846375, 0.0, 0.57434051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.71890112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.58597115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29861623, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29007666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.92547543, 0.0, 0.0, 0.78395908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.78435353, 0.0, 0.0, 0.0, 0.0, 0.20052668000000257, 0.0, 0.96441936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01143797, 0.0, 0.0, 0.0, 0.0, 0.91011617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29058066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve optimal value and optimal solution\n",
    "opt_val = mod.objval\n",
    "print(\"Optimal cost:\",opt_val)\n",
    "\n",
    "x_opt = [x[i,j].x for i in range(m) for j in range(n)]\n",
    "print(x_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "These are just two simple examples of how to solve linear programs using Gurobi. The general principles used above can be extended to much larger and more complex optimization models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
